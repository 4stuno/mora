# MAS para Plataforma de Ensino - Sistema Multiagente com RAG e Ontologia DL

Sistema multiagente que integra ontologia OWL 2 DL, RAG hÃ­brido e agentes baseados em LLM para suporte a plataformas de ensino.

---

## ğŸ“‹ Ãndice

1. [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
2. [ConfiguraÃ§Ã£o](#configuraÃ§Ã£o)
3. [Como Usar](#como-usar)
4. [Testes](#testes)
5. [Estrutura do Projeto](#estrutura-do-projeto)

---

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.10 ou superior
- Java 8+ (opcional, para HermiT reasoner)

### Passo 1: Instalar DependÃªncias

```bash
pip install -r requirements.txt
```

**Nota:** Se der erro com alguma dependÃªncia, instale em grupos:

```bash
# Grupo 1: Essenciais
pip install numpy pandas fastapi uvicorn pydantic

# Grupo 2: LangChain
pip install langchain langchain-openai langgraph langchain-community langchain-ollama

# Grupo 3: RAG
pip install sentence-transformers faiss-cpu

# Grupo 4: Ontologia
pip install rdflib owlready2 sparqlwrapper

# Grupo 5: Resto
pip install -r requirements.txt
```

---

## âš™ï¸ ConfiguraÃ§Ã£o

### OpÃ§Ã£o 1: Usar Llama Local (Recomendado - Gratuito)

**1. Instalar Ollama:**
- Windows: Baixe de https://ollama.com/download/windows
- Linux/Mac: `curl -fsSL https://ollama.com/install.sh | sh`

**2. Baixar modelo Llama:**
```bash
ollama pull llama3.2
```

**3. Criar arquivo `.env` na raiz do projeto:**
```bash
USE_OLLAMA=true
OLLAMA_MODEL=llama3.2
```

**4. Instalar dependÃªncia:**
```bash
pip install langchain-ollama
```

**5. Iniciar Ollama (em terminal separado):**
```bash
ollama serve
```

### OpÃ§Ã£o 2: Usar OpenAI (Pago)

**1. Obter chave API:**
- Acesse: https://platform.openai.com/api-keys
- Crie uma chave

**2. Criar arquivo `.env`:**
```bash
OPENAI_API_KEY=sua_chave_aqui
OPENAI_MODEL=gpt-4
```

**Nota:** Se nÃ£o configurar nenhum modelo, o sistema tentarÃ¡ usar Ollama automaticamente.

---

## ğŸ“š Como Usar

### 1. Carregar Documentos na Base de Conhecimento

**Primeira vez:** Carregue os documentos Markdown para criar o Ã­ndice de busca vetorial.

```bash
python scripts/load_documents.py
```

**O que faz:**
- Carrega documentos de `documents/markdown/`
- Cria embeddings usando sentence-transformers
- Salva Ã­ndice FAISS em `data/vector_store/`

**SaÃ­da esperada:**
```
Carregando documentos...
Documentos carregados: 3
Indexando documentos...
Salvando Ã­ndice...
Ãndice salvo com 7 chunks
ConcluÃ­do!
```

### 2. Executar Competency Questions (CQs)

Testa as 10 Competency Questions que dependem de inferÃªncia DL:

```bash
python scripts/run_cqs.py
```

**O que faz:**
- Executa consultas SPARQL Ã  ontologia
- Testa raciocÃ­nio DL (classificaÃ§Ã£o, consistÃªncia, realizaÃ§Ã£o)
- Mostra resultados de cada CQ

### 3. Ver Exemplos de Uso

Executa exemplos prÃ¡ticos do sistema:

```bash
python scripts/example_usage.py
```

**O que faz:**
- Demonstra consultas bÃ¡sicas
- Mostra sistema de recomendaÃ§Ã£o
- Testa consultas SPARQL diretas
- Demonstra recuperaÃ§Ã£o hÃ­brida

### 4. Iniciar API REST

Inicia servidor FastAPI para acesso via HTTP:

```bash
python -m api.main
```

**Acessar:**
- API: http://localhost:8000
- DocumentaÃ§Ã£o: http://localhost:8000/docs
- Health check: http://localhost:8000/health

### 5. Iniciar Frontend (Interface Web)

**OpÃ§Ã£o 1: Servidor HTTP simples**
```bash
# Terminal 1: Iniciar API
python -m api.main

# Terminal 2: Iniciar servidor HTTP para frontend
cd frontend
python -m http.server 8080
```

Depois acesse: http://localhost:8080

**OpÃ§Ã£o 2: Abrir direto no navegador**
```bash
# Terminal 1: Iniciar API
python -m api.main

# Terminal 2: Abrir frontend/index.html no navegador
# (Arraste o arquivo para o navegador ou use: start frontend/index.html)
```

**Funcionalidades do Frontend:**
- ğŸ’¬ **Consultas**: Interface de chat para testar queries
- â“ **Competency Questions**: Executar CQs com um clique
- ğŸ§  **Reasoner DL**: Testar classificaÃ§Ã£o, consistÃªncia, realizaÃ§Ã£o
- â„¹ï¸ **Sobre**: Visualizar arquitetura e status do sistema

**Endpoints disponÃ­veis:**
- `POST /query` - Processar query atravÃ©s dos agentes
- `POST /sparql` - Executar consulta SPARQL
- `POST /consistency` - Verificar consistÃªncia ontolÃ³gica
- `GET /courses` - Listar cursos
- `GET /tasks?student_id=...` - Listar tarefas de estudante

### 5. Usar Programaticamente

```python
from agents.orchestrator import AgentOrchestrator
from rag.vector_store import VectorStore
from rag.sparql_query import SPARQLQueryEngine
from rag.hybrid_retriever import HybridRetriever

# Inicializar componentes
vector_store = VectorStore()
vector_store.load()  # Carrega Ã­ndice existente

sparql_engine = SPARQLQueryEngine()
retriever = HybridRetriever(vector_store, sparql_engine)
orchestrator = AgentOrchestrator(retriever)

# Processar query
result = orchestrator.process_query(
    "Quais cursos estÃ£o disponÃ­veis para o estudante Ana?",
    context={'student_id': 'http://www.exemplo.org/ead-ontologia#Estudante_Ana'}
)

print(result['response'])
print(f"CitaÃ§Ãµes: {result['citations']}")
```

---

## ğŸ§ª Testes

### Teste RÃ¡pido de Imports

Verifica se todas as dependÃªncias estÃ£o instaladas:

```bash
python -c "import numpy, pandas, fastapi, langchain, rdflib, owlready2; print('âœ… Todas as dependÃªncias OK')"
```

### Teste do Vector Store

```bash
python -c "from rag.vector_store import VectorStore; vs = VectorStore(); vs.load(); print(f'âœ… Vector Store OK - {len(vs.documents)} chunks')"
```

### Teste do SPARQL

```bash
python -c "from rag.sparql_query import SPARQLQueryEngine; e = SPARQLQueryEngine(); print(f'âœ… SPARQL OK - {len(e.get_courses())} cursos')"
```

### Teste do Reasoner DL

```bash
python -c "from ontology.reasoner import DLReasoner; r = DLReasoner(); print(f'âœ… Reasoner OK - Consistente: {r.check_consistency()[\"consistent\"]}')"
```

### Teste Completo do Sistema

```python
# Criar arquivo teste_sistema.py
from rag.vector_store import VectorStore
from rag.sparql_query import SPARQLQueryEngine
from rag.hybrid_retriever import HybridRetriever
from agents.orchestrator import AgentOrchestrator

# Inicializar
vs = VectorStore()
vs.load()
se = SPARQLQueryEngine()
hr = HybridRetriever(vs, se)
orch = AgentOrchestrator(hr)

# Testar
result = orch.process_query("Quais cursos estÃ£o disponÃ­veis?")
print("âœ… Sistema funcionando!")
print(f"Resposta: {result['response'][:100]}...")
```

---

## ğŸ“ Estrutura do Projeto

```
ws-mora/
â”œâ”€â”€ agents/                    # Agentes do sistema
â”‚   â”œâ”€â”€ base_agent.py         # Classe base para agentes
â”‚   â”œâ”€â”€ coordinator.py        # Agente coordenador
â”‚   â”œâ”€â”€ student.py            # Agente estudante
â”‚   â”œâ”€â”€ recommendation.py     # Agente de recomendaÃ§Ã£o
â”‚   â”œâ”€â”€ lms.py               # Agente LMS
â”‚   â””â”€â”€ orchestrator.py      # Orquestrador (LangGraph)
â”‚
â”œâ”€â”€ rag/                      # Sistema RAG hÃ­brido
â”‚   â”œâ”€â”€ vector_store.py       # Busca vetorial (FAISS)
â”‚   â”œâ”€â”€ sparql_query.py       # Consultas SPARQL
â”‚   â””â”€â”€ hybrid_retriever.py   # Retriever hÃ­brido
â”‚
â”œâ”€â”€ ontology/                 # Ontologia e reasoner
â”‚   â”œâ”€â”€ reasoner.py           # Reasoner DL (HermiT/Pellet)
â”‚   â”œâ”€â”€ competency_questions.md  # DocumentaÃ§Ã£o das CQs
â”‚   â””â”€â”€ reasoning_notebook.ipynb  # Notebook de raciocÃ­nio
â”‚
â”œâ”€â”€ documents/                # Base documental
â”‚   â”œâ”€â”€ markdown/            # Documentos Markdown
â”‚   â””â”€â”€ metadata.json        # Metadados dos documentos
â”‚
â”œâ”€â”€ api/                      # API REST
â”‚   â””â”€â”€ main.py              # Servidor FastAPI
â”‚
â”œâ”€â”€ scripts/                  # Scripts auxiliares
â”‚   â”œâ”€â”€ load_documents.py    # Carregar documentos
â”‚   â”œâ”€â”€ run_cqs.py          # Executar CQs
â”‚   â”œâ”€â”€ example_usage.py    # Exemplos de uso
â”‚   â””â”€â”€ init_system.py      # Inicializar sistema
â”‚
â”œâ”€â”€ data/                     # Dados gerados
â”‚   â””â”€â”€ vector_store/        # Ãndice FAISS
â”‚
â”œâ”€â”€ ontologia_mora.owl        # Ontologia OWL
â”œâ”€â”€ requirements.txt         # DependÃªncias Python
â””â”€â”€ README.md               # Este arquivo
```

---

## ğŸ¯ Fluxo de Trabalho Recomendado

### Primeira Vez

1. **Instalar dependÃªncias:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Configurar modelo LLM:**
   - Criar `.env` com `USE_OLLAMA=true` (ou `OPENAI_API_KEY=...`)
   - Se usar Ollama: `ollama pull llama3.2` e `ollama serve`

3. **Carregar documentos:**
   ```bash
   python scripts/load_documents.py
   ```

4. **Testar CQs:**
   ```bash
   python scripts/run_cqs.py
   ```

5. **Ver exemplos:**
   ```bash
   python scripts/example_usage.py
   ```

### Uso DiÃ¡rio

1. **Iniciar Ollama (se usar):**
   ```bash
   ollama serve
   ```

2. **Usar o sistema:**
   - Via API: `python -m api.main`
   - Via Python: usar `AgentOrchestrator` como no exemplo acima

---

## ğŸ”§ SoluÃ§Ã£o de Problemas

### Erro: "No module named X"

```bash
pip install X
```

### Erro: "Vector store not found"

```bash
python scripts/load_documents.py
```

### Erro: "Ollama connection failed"

Certifique-se de que:
1. Ollama estÃ¡ instalado
2. Modelo foi baixado: `ollama pull llama3.2`
3. Ollama estÃ¡ rodando: `ollama serve`

### Erro: "OpenAI API key not found"

Configure no `.env`:
- `OPENAI_API_KEY=sua_chave` (se usar OpenAI)
- OU `USE_OLLAMA=true` (se usar Ollama)

### Erro: "Ontology not found"

Verifique se `ontologia_mora.owl` estÃ¡ na raiz do projeto.

### âš ï¸ Reasoner DL: "UnsupportedDatatypeException: xsd:date"

**Problema:** A ontologia usa `xsd:date`, que nÃ£o Ã© suportado pelo HermiT (apenas `xsd:dateTime` estÃ¡ no OWL 2 datatype map).

**SoluÃ§Ã£o:**
- **OpÃ§Ã£o 1:** O sistema continua funcionando normalmente! As CQs 1-5 funcionam perfeitamente via SPARQL.
- **OpÃ§Ã£o 2:** Para usar reasoner completo, substitua `xsd:date` por `xsd:dateTime` na ontologia.

**Nota:** Isso nÃ£o afeta o funcionamento do sistema - apenas limita algumas inferÃªncias DL avanÃ§adas. SPARQL e todas as funcionalidades principais continuam funcionando.

---

## ğŸ“Š Componentes Principais

### Agentes

- **CoordinatorAgent**: Orquestra tarefas e resolve conflitos
- **StudentAgent**: Representa estudantes e suas aÃ§Ãµes
- **RecommendationAgent**: Fornece recomendaÃ§Ãµes personalizadas
- **LMSAgent**: Gerencia estado da plataforma e triplestore

### RAG HÃ­brido

- **Vector Store**: Busca semÃ¢ntica em documentos (FAISS)
- **SPARQL Engine**: Consultas estruturadas Ã  ontologia
- **Hybrid Retriever**: Combina ambas as fontes

### Reasoner DL

- **ClassificaÃ§Ã£o**: Infere hierarquia de classes
- **ConsistÃªncia**: Verifica contradiÃ§Ãµes
- **RealizaÃ§Ã£o**: Infere tipos de indivÃ­duos
- **MaterializaÃ§Ã£o**: Adiciona triplas inferidas

---

## ğŸ“ Notas Importantes

1. **Primeira execuÃ§Ã£o:** Sempre execute `load_documents.py` antes de usar o sistema
2. **Ollama:** Deve estar rodando (`ollama serve`) para os agentes funcionarem
3. **Ontologia:** O arquivo `ontologia_mora.owl` deve estar na raiz
4. **Sem LLM:** VocÃª pode testar SPARQL, CQs e Reasoner sem configurar LLM

---

## ğŸ“ Para o Projeto AcadÃªmico

Este sistema atende todos os requisitos:

- âœ… Ontologia OWL 2 DL com inferÃªncia
- âœ… RAG hÃ­brido (vetorial + SPARQL)
- âœ… Agentes baseados em LLM (orquestrados com LangGraph)
- âœ… Respostas citadas (documentos + IRIs)
- âœ… VerificaÃ§Ã£o de consistÃªncia ontolÃ³gica
- âœ… 10 Competency Questions implementadas

---

## ğŸ‘¥ Autores

- JÃºlio Cesar
- Carlos Guedes

---

## ğŸ“„ LicenÃ§a

Projeto acadÃªmico - Uso educacional.

